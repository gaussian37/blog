---
layout: post
title:  Hugo Larochelle의 딥러닝 강의
date: 2000-01-01 00:00:00
img: dl/larochelle/table/0.png
categories: [dl-larochelle] 
tags: [hugo larochelle, deep learning] # add tag
---

<br>

- 참조 자료 : http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html
- 강의 목록 : https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH

<br>

- 이 강의는 Hugo Larochelle의 딥러닝 강의를 정리한 목차 입니다.

<br>

- [1.1. : Feedforward neural network - artificial neuron]()
- [1.2. : Feedforward neural network - activation function]()
- [1.3. : Feedforward neural network - capacity of single neuron]()
- [1.4. : Feedforward neural network - multilayer neural network]()
- [1.5. : Feedforward neural network - capacity of neural network]()
- [1.6. : Feedforward neural network - biological inspiration]()
- [2.1. : Training neural networks - empirical risk minimization]()
- [2.2. : Training neural networks - loss function]()
- [2.3. : Training neural networks - output layer gradient]()
- [2.4. : Training neural networks - hidden layer gradient]()
- [2.5. : Training neural networks - activation function derivative]()
- [2.6. : Training neural networks - parameter gradient]()
- [2.7. : Training neural networks - backpropagation]()
- [2.8. : Training neural networks - regularization]()
- [2.9. : Training neural networks - parameter initialization]()
- [2.10. : Training neural networks - model selection]()
- [2.11. : Training neural networks - optimization]()
- [3.1. : Conditional random fields - motivation]()
- [3.2. : Conditional random fields - linear chain CRF]()
- [3.3. : Conditional random fields - context window]()
- [3.4. : Conditional random fields - computing the partition function]()
- [3.5. : Conditional random fields - computing marginals]()
- [3.6. : Conditional random fields - performing classification]()
- [3.7. : Conditional random fields - factors, sufficient statistics and linear CRF]()
- [3.8. : Conditional random fields - Markov network]()
- [3.9. : Conditional random fields - factor graph]()
- [3.10. : Conditional random fields - belief propagation]()
- [4.1. : Training CRFs - loss function]()
- [4.2. : Training CRFs - unary log-factor gradient]()
- [4.3. : Training CRFs - pairwise log-factor gradient]()
- [4.4. : Training CRFs - discriminative vs. generative learning]()
- [4.5. : Training CRFs - maximum-entropy Markov model]()
- [4.6. : Training CRFs - hidden Markov model]()
- [4.7. : Training CRFs - general conditional random field]()
- [4.8. : Training CRFs - pseudolikelihood]()
- [5.1. : Restricted Boltzmann machine - definition]()
- [5.2. : Restricted Boltzmann machine - inference]()
- [5.3. : Restricted Boltzmann machine - free energy]()
- [5.4. : Restricted Boltzmann machine - contrastive divergence]()
- [5.5. : Restricted Boltzmann machine - contrastive divergence (parameter update)]()
- [5.6. : Restricted Boltzmann machine - persistent CD]()
- [5.7. : Restricted Boltzmann machine - example]()
- [5.8. : Restricted Boltzmann machine - extensions]()
- [6.1. : Autoencoder - definition]()
- [6.2. : Autoencoder - loss function]()
- [6.3. : Autoencoder - example]()
- [6.4. : Autoencoder - linear autoencoder]()
- [6.5. : Autoencoder - undercomplete vs. overcomplete hidden layer]()
- [7.2. : Deep learning - difficulty of training]()
- [7.3. : Deep learning - unsupervised pre-training]()
- [7.4. : Deep learning - example]()
- [7.5. : Deep learning - dropout]()
- [7.6. : Deep learning - deep autoencoder]()
- [7.7. : Deep learning - deep belief network]()
- [7.8. : Deep learning - variational bound]()
- [7.9. : Deep learning - DBN pre-training]()
- [8.1. : Sparse coding - definition]()
- [8.2. : Sparse coding - inference (ISTA algorithm)]()
- [8.3. : Sparse coding - dictionary update with projected gradient descent]()
- [8.4. : Sparse coding - dictionary update with block-coordinate descent]()
- [8.5. : Sparse coding - dictionary learning algorithm]()
- [8.6. : Sparse coding - online dictionary learning algorithm]()
- [8.7. : Sparse coding - ZCA preprocessing]()
- [9.7. : Computer vision - object recognition]()
- [9.8. : Computer vision - example]()
- [9.9. : Computer vision - data set expansion]()
- [9.10 . : Computer vision - convolutional RBM]()
- [10.1. : Natural language processing - motivation]()
- [10.2. : Natural language processing - preprocessing]()
- [10.3. : Natural language processing - one-hot encoding]()
- [10.4. : Natural language processing - word representations]()
- [10.5. : Natural language processing - language modeling]()
- [10.6. : Natural language processing - neural network language model]()
- [10.7. : Natural language processing - hierarchical output layer]()
- [10.8. : Natural language processing - word tagging]()
- [10.9. : Natural language processing - convolutional network]()
- [10.10. : Natural language processing - multitask learning]()
- [10.11. : Natural language processing - recursive network]()
- [10.12. : Natural language processing - merging representations]()
- [10.13. : Natural language processing - tree inference]()