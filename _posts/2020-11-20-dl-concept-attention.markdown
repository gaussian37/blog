---
layout: post
title: Attention 모델과 Seq2seq with Attention
date: 2020-11-20 00:00:00
img: dl/concept/attention/0.png
categories: [dl-concept]
tags: [attention, seq2seq] # add tag
---

<br>

[deep learning 관련 글 목차](https://gaussian37.github.io/dl-concept-table/)

<br>

- 참조 : fastcampus 딥러닝/인공지능 올인원 패키지 Online.
- 참조 : 시퀀스 투 시퀀스 + 어텐션 모델 (https://www.youtube.com/watch?v=WsQLdu2JMgI&feature=youtu.be)
- 참조 : 모두를 위한 기계번역 (https://youtu.be/N4E53ZcUBJs)
- 참조 : Pytorch Seq2Seq Tutorial for Machine Translation (https://www.youtube.com/watch?v=EoGUlvhRYpk&feature=youtu.be)
- 참조 : Pytorch Seq2Seq with Attention for Machine Translation (https://youtu.be/sQUqQddQtB4)







<br>

[deep learning 관련 글 목차](https://gaussian37.github.io/dl-concept-table/)

<br>