---
layout: post
title: Machine Learning Yearning (Andrew Ng) 요약
date: 2020-11-08 00:00:00
img: ml/concept/ml_yearning/0.png
categories: [ml-concept] 
tags: [딥러닝, 머신러닝, Andrew Ng, Machine Learning Yearning] # add tag
---

<br>

[machine learning 관련 글 목차](https://gaussian37.github.io/ml-concept-table/)

<br>

- 원문 링크 : https://gallery.mailchimp.com/dc3a7ef4d750c0abfc19202a3/files/5dd91615-3b3f-4f5d-bbfb-4ebd8608d330/Ng_MLY01_13.pdf
- 참조 : https://github.com/hoya012/Machine-Learning-Yearning-Korean-Translation
- 이 글은 Andrew Ng의 Machine Learning Yearing을 제가 필요한 내용에 맞게 재해석하여 요약한 글입니다.


<br>

## **목차**

<br>

- ### **1. 왜 머신러닝에 대한 전략을 알아야 하는가?**
- ### **2. 이 책을 사용 하는 방법 (Skip)**
- ### **3. 이 책을 읽기전 미리 알아야 하는 것과 사용되는 표기법(Skip)**
- ### **4. 규모가 머신러닝의 진보를 이끈다.**

<br>

### 개발용 데이터셋과 테스트용 데이터셋을 설정하는 것에 대하여

<br>

- ### **5. 개발 데이터셋과 테스트 데이터셋**
- ### **6. 개발/테스트 데이터셋은 같은 분포의 데이터로 구성되어야 한다**
- ### **7. 개발/테스트 데이터셋이 얼마나 커야 하는가?**
- ### **8. 알고리즘 최적화를 위해서 단일-숫자 평가지표를 설정하는것**
- ### **9. 최적화와 만족화라는 평가 지표에 대해서**
- ### **10. 개발 데이터셋과 평가지표로 개발 사이클 순환 속도를 빠르게**
- ### **11. 개발/테스트 데이터셋과 평가지표를 언제 바꿔야 하는가?**
- ### **12. 요약: 개발 데이터셋과 테스트 데이터셋을 설정하는 것에 관하여**

<br>

### **기본적인 에러 분석에 대하여**

<br>

- ### **13. 빨리 시스템을 만들어 보고, 개발 사이클의 순환을 빠르게 하자**
- ### **14. 에러 분석: 아이디어에 대한 평가를 위해 개발 데이터셋을 살펴보는 것**
- ### **15. 에러 분석 중간에 여러가지 아이디어를 동시에 판단해 보는 것**
- ### **16. 개발/테스트 데이터셋의 잘못 레이블링된 데이터를 정리하는 것**
- ### **17. 큰 사이즈의 개발 데이터셋이 있는 경우, 두개의 부분집합으로 이를 나누고, 그 중 하나만 관찰하는 것**
- ### **18. "눈알"과 "블랙박스" 개발데이터셋은 얼마나 커야 할까?**
- ### **19. 요약: 기본적인 에러 분석에 관하여**

<br>

### **편향과 분산에 대하여**

<br>

- ### **20. 편향과 분산: 에러를 일으키는 두 가지 큰 원인**
- ### **21. 편향과 분산의 예**
- ### **22. 최적의 에러율과 비교하는 것**
- ### **23. 편향과 분산 문제 해결방법에 대한 고심**
- ### **24. 편향 vs. 분산의 균형 대립**
- ### **25. 피할 수 있는 편향을 줄이기 위한 기법들**
- ### **26. 학습 데이터셋에 대한 에러 분석**
- ### **27. 분산치를 줄이기 위한 기법들**

<br>

### **학습 곡선(Learning Curve)에 대하여**

<br>

- ### **28. 편향과 분산을 진단하는 것: 학습 곡선**
- ### **29. 학습 데이터셋에 대한 에러의 곡선을 그리는 것**
- ### **30. 학습 곡선을 해석하는 것: 높은 편향치**
- ### **31. 학습 곡선을 해석하는 것: 그 외의 상황**
- ### **32. 학습 곡선들을 그리는 것**

<br>

- ### **인간 수준의 성능과 비교하는 것에 대하여**

<br>

- ### **33. 왜 사람-수준의 성능과 비교해야 하는가?**
- ### **34. 어떻게 사람-수준의 성능을 정의할 것인가?**
- ### **35. 사람-수준의 성능을 넘어서는 것**

<br>

### **다른 데이터 분포에 대하여 트레이닝과 테스트하는 것에 대하여**

<br>

- ### **36. 다른 분포로 부터 구성되는 학습, 테스트 데이터셋을 언제 사용해야 하는가?**
- ### **37. 모든 데이터를 사용해야하는지 어떻게 결정을 내려야 하는가?**
- ### **38. 일관적이지 못한 데이터를 포함시키기 위한 결정을 어떻게 내려야 하는가?**
- ### **39. 데이터에 가중치를 주는 것**
- ### **40. 학습 데이터셋에서 개발 데이터셋으로 일반화 하는 것**
- ### **41. 편향과 분산을 표현/해결하는 것**
- ### **42. 데이터 미스매치를 표현/해결하는 것**
- ### **43. 인공적인 데이터 합성에 대하여**

<br>

### **추론 알고리즘을 디버깅 하는 것에 대하여**

<br>

- ### **44. 최적화 검증 테스트(The Optimization Verification test)**
- ### **45. 최적화 검증 테스트의 일반적인 형태**
- ### **46. 강화학습의 예**

<br>

## **End-to-End 딥러닝에 대하여**

<br>

- ### **47. End-to-End 학습의 등장**
- ### **48. End-to-End 학습의 다른 예**
- ### **49. End-to-End 학습의 장단점**
- ### **50. 파이프라인의 컴포넌트를 선택하는 것: 데이터 수집의 가능성**
- ### **51. 파이프라인의 컴포넌트를 선택하는 것: 작업의 간결성**
- ### **52. 직접적으로 부유한(rich) 출력값을 학습하는 것**

<br>

### **부분별로 수행하는 에러 분석**

<br>

- ### **53. 부분/컴포넌트별로 수행하는 에러 분석**
- ### **54. 에러를 특정 컴포넌트의 잘못으로 분류하는것**
- ### **55. 에러를 특정 컴포넌트의 잘못으로 분류하는 일반적인 방법**
- ### **56. 사람-수준의 성능과 각 컴포넌트를 비교하여 에러분석을 수행하는 것**
- ### **57. ML 파이프라인의 결함을 발견하는 것**

<br>

- ## **결말**

<br>

- ### **58. super hero 팀을 결성하고 이 문서를 공유할 것**

<br>

### **1. 왜 머신러닝에 대한 전략을 알아야 하는가?**

<br>

- 머신러닝 알고리즘을 이용하여 컴퓨터 비전 시스템을 구축할 때, 다양한 아이디어를 가질 수 있습니다. 예를 들어 다음과 같습니다.
- ① 더 많은 데이터의 수집. 즉, 더 많은 사진을 확보합니다.
- ② 더 다양한 트레이닝 셋을 수집합니다. 
- ③ 더 긴 시간동안 더 많은 횟수의 Grandient Descent를 반복(iteration) 하여 학습시킵니다.
- ④ 더 많은 레이어, 히든 유닛, 또는 파라메터로 구성된 더 큰 뉴럴 네트워크 모델을 사용해 봅니다.
- ⑤ 반대로 작은 뉴럴 네트워크 를 시도해 보는 방법도 있습니다.
- ⑥ L2 regularization와 같은 학습에 도움이 되는 테크닉들을 시도해 볼 수 있습니다.
- ⑦ 활성 함수 또는 히든 유닛의 개수등에 변화 를 주어 뉴럴 네트워크의 설계를 변경하는 방법도 있을 수 있습니다.
- …
- 위와 같은 아이디어가 적중할 때에는 성능 개선될 수 있지만 반대로 잘못 접근하면 시간낭비만 할 수 있습니다.
- 이 `글의 목적`은 **위와 같은 아이디어를 적중하는 데 도움이 되기 위함**입니다.

<br>

- 아래 두 내용은 Skip하였습니다.
- 2. 이 책을 사용 하는 방법
- 3. 이 책을 읽기전 미리 알아야 하는 것과 사용되는 표기법

<br>

### **4. 규모가 머신러닝의 진보를 이끈다.**

<br>

- 딥러닝의 발전에는 다음 2가지 요소가 있었습니다.
- `데이터의 입수 가능성` : 사람들이 디지털 장비에 갈수록 더 많은 시간을 소비하고 있습니다. 이러한 디지털 장비 사용은 많은 양의 데이터를 생성하게 되고, 이 데이터는 학습 알고리즘에 인풋 데이터로서 활용될 수 있게 됩니다.
- `계산 규모` : 최근에야 비로소 거대한 데이터로 부터 이득을 취할 수 있는 큰 사이즈의 인공신경망을 학습 시킬 수 있게 되었다.
- 더 많은 데이터를 축적 하더라도, 예전의 학습 알고리즘 (logistic regression과 같은) 에 대한 성능은 보통 일직선으로 수렴 하게 됩니다. (특정 시점 이후 더 이상 개선이 안되는 현상). 러닝 커브가 평평해 지고 더 많은 데이터를 입력하더라도 성능은 개선되지 못하였습니다.

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/1.png" alt="Drawing" style="width: 800px;"/></center>
<br>

- 마치 예전의 알고리즘들은 수집된 거대한 데이터를 어떻게 사용해야 하는지 모르는 것 같아 보였습니다. 하지만 만약 작은 인공신경망을 동일한 지도학습 문제에 적용한다면, 약간은 더 나은 결과 를 얻을 수도 있습니다.

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/2.png" alt="Drawing" style="width: 800px;"/></center>
<br>

- 여기서 `작은 인공신경망`은 작은 수의 "히든 유닛", "레이어", "파라메터"로 구성된 인공신경망을 의미합니다. 계속해서 더 큰 인공신경망을 이용하여 학습을 시도하는 경우에 더 나은 결과 를 얻을 수 있습니다.
- 또한 위 그래프를 통해 작은 양의 데이터에서도 인공신경망이 더 나은 성능을 가진다는 것을 알 수 있습니다. 
- 이 현상은 거대한 데이터에 대하여 인공신경망이 꽤 나은 결과를 보여주는 현상과는 약간 다른 양상을 보여줍니다. 작은 양의 데이터 에 대하여, 얼마나 features들이 수작업으로 잘 엔지니어링 되었는지 에 따라서, 전통적인 알고리즘이 더 좋은 결과를 보일 수도 있고 그렇지 않을 수도 있습니다. 
- 예를 들어서, 20개의 학습 데이터가 있는 경우, logistic regression을 사용하는 것과 인공 신경망을 사용하는 것 사이에 큰 차이가 없을 수 있습니다. 이 때는 학습 데이터의 feature에 대한 엔지니어링된 정도가 알고리즘을 선택하는것 보다 큰 효과가 있을 수 있습니다.
- 하지만 만약 100만개의 학습 데이터가 있는 경우 거의 항상 인공신경망 을 사용하는게 좋다고 볼 수 있습니다.

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/3.png" alt="Drawing" style="width: 800px;"/></center>
<br>

- 위 그래프를 보면 매우 큰 인공신경망에 학습을 시도할 때에 최고의 성능을 얻을 수 있습니다. 위 그림의 녹색 곡선 처럼 큰 인공 신경망에는 거대한 양의 데이터가 필요합니다. 물론 인공 신경망의 구조를 설계하는 다른 많은 부분이 중요하고 이에 대한 많은 발전이 이루어 지고 있습니다.하지만 알고리즘의 성능을 향상 시키기 위한 가장 안정적인 방법 중 하나는 여전히 ① 더 큰 네트워크 의 사용과 ② 더 많은 데이터 를 모으는 것에 있습니다.
- ①, ②를 성취하기 위한 과정은 매우 복잡하다. 앞으로 다룰 글에서는 이 방법에 대해서 자세하게 다룰 예정이다. 우선 전통적인 알고리즘과 인공신경망 모두에게 유용한 일반적인 전략에 대해 설명하고, 그리고 나서 딥러닝 시스템을 구축하기 위한 가장 현대적인 방법에 대하여 다루겠습니다.

<br>

### **5. 개발 데이터셋과 테스트 데이터셋**


<br>

### **6. 개발/테스트 데이터셋은 같은 분포의 데이터로 구성되어야 한다**


<br>

### **7. 개발/테스트 데이터셋이 얼마나 커야 하는가?**


<br>

### **8. 알고리즘 최적화를 위해서 단일-숫자 평가지표를 설정하는것**

<br>

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/4.png" alt="Drawing" style="width: 800px;"/></center>
<br>

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/5.png" alt="Drawing" style="width: 800px;"/></center>
<br>

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/6.png" alt="Drawing" style="width: 800px;"/></center>
<br>


<br>

### **9. 최적화와 만족화라는 평가 지표에 대해서**

<br>

<br>
<center><img src="../assets/img/ml/concept/ml_yearning/7.png" alt="Drawing" style="width: 800px;"/></center>
<br>


<br>

### **10. 개발 데이터셋과 평가지표로 개발 사이클 순환 속도를 빠르게**

<br>


<br>
<center><img src="../assets/img/ml/concept/ml_yearning/8.png" alt="Drawing" style="width: 800px;"/></center>
<br>

<br>

### **11. 개발/테스트 데이터셋과 평가지표를 언제 바꿔야 하는가?**


<br>

### **12. 요약: 개발 데이터셋과 테스트 데이터셋을 설정하는 것에 관하여**


<br>

### **13. 빨리 시스템을 만들어 보고, 개발 사이클의 순환을 빠르게 하자**


<br>

### **14. 에러 분석: 아이디어에 대한 평가를 위해 개발 데이터셋을 살펴보는 것**


<br>

### **15. 에러 분석 중간에 여러가지 아이디어를 동시에 판단해 보는 것**


<br>

### **16. 개발/테스트 데이터셋의 잘못 레이블링된 데이터를 정리하는 것**


<br>

### **17. 큰 사이즈의 개발 데이터셋이 있는 경우, 두개의 부분집합으로 이를 나누고, 그 중 하나만 관찰하는 것**


<br>

### **18. "눈알"과 "블랙박스" 개발데이터셋은 얼마나 커야 할까?**


<br>

### **19. 요약: 기본적인 에러 분석에 관하여**


<br>

### **20. 편향과 분산: 에러를 일으키는 두 가지 큰 원인**


<br>

### **21. 편향과 분산의 예**


<br>

### **22. 최적의 에러율과 비교하는 것**


<br>

### **23. 편향과 분산 문제 해결방법에 대한 고심**


<br>

### **24. 편향 vs. 분산의 균형 대립**


<br>

### **25. 피할 수 있는 편향을 줄이기 위한 기법들**


<br>

### **26. 학습 데이터셋에 대한 에러 분석**


<br>

### **27. 분산치를 줄이기 위한 기법들**


<br>

### **28. 편향과 분산을 진단하는 것: 학습 곡선**


<br>

### **29. 학습 데이터셋에 대한 에러의 곡선을 그리는 것**


<br>

### **30. 학습 곡선을 해석하는 것: 높은 편향치**


<br>

### **31. 학습 곡선을 해석하는 것: 그 외의 상황**


<br>

### **32. 학습 곡선들을 그리는 것**


<br>

### **인간 수준의 성능과 비교하는 것에 대하여**


<br>

### **33. 왜 사람-수준의 성능과 비교해야 하는가?**


<br>

### **34. 어떻게 사람-수준의 성능을 정의할 것인가?**


<br>

### **35. 사람-수준의 성능을 넘어서는 것**


<br>

### **36. 다른 분포로 부터 구성되는 학습, 테스트 데이터셋을 언제 사용해야 하는가?**


<br>

### **37. 모든 데이터를 사용해야하는지 어떻게 결정을 내려야 하는가?**


<br>

### **38. 일관적이지 못한 데이터를 포함시키기 위한 결정을 어떻게 내려야 하는가?**


<br>

### **39. 데이터에 가중치를 주는 것**


<br>

### **40. 학습 데이터셋에서 개발 데이터셋으로 일반화 하는 것**


<br>

### **41. 편향과 분산을 표현/해결하는 것**


<br>

### **42. 데이터 미스매치를 표현/해결하는 것**


<br>

### **43. 인공적인 데이터 합성에 대하여**


<br>

### **44. 최적화 검증 테스트(The Optimization Verification test)**


<br>

### **45. 최적화 검증 테스트의 일반적인 형태**


<br>

### **46. 강화학습의 예**


<br>

### **47. End-to-End 학습의 등장**


<br>

### **48. End-to-End 학습의 다른 예**


<br>

### **49. End-to-End 학습의 장단점**


<br>

### **50. 파이프라인의 컴포넌트를 선택하는 것: 데이터 수집의 가능성**


<br>

### **51. 파이프라인의 컴포넌트를 선택하는 것: 작업의 간결성**


<br>

### **52. 직접적으로 부유한(rich) 출력값을 학습하는 것**


<br>

### **53. 부분/컴포넌트별로 수행하는 에러 분석**


<br>

### **54. 에러를 특정 컴포넌트의 잘못으로 분류하는것**


<br>

### **55. 에러를 특정 컴포넌트의 잘못으로 분류하는 일반적인 방법**


<br>

### **56. 사람-수준의 성능과 각 컴포넌트를 비교하여 에러분석을 수행하는 것**


<br>

### **57. ML 파이프라인의 결함을 발견하는 것**


<br>

### **58. super hero 팀을 결성하고 이 문서를 공유할 것**




<br>

[machine learning 관련 글 목차](https://gaussian37.github.io/ml-concept-table/)

<br>
