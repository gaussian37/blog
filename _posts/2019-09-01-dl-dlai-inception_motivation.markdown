---
layout: post
title: Inception Motivation
date: 2019-09-01 01:00:00
img: dl/dlai/dlai.png
categories: [dl-dlai] 
tags: [python, deep learning, CNN, Inception] # add tag
---

- 이번 글에서는 `Inception`의 핵심이 되는 컨셉에 대하여 알아보도록 하겠습니다.
- 합성곱 신경망을 디자인할 때, 어떤 사이즈의 필터를 사용할 지 풀링을 사용할 지 고민을 해야하는데 `Inception`에서는 여러가지 필터를 다 사용해 보자는 컨셉을 가집니다.
- 이렇게 사용하면 네트워크가 복잡해지기는 하지만 성능은 뛰어나지기 때문입니다. 한번 살펴보겠습니다.

<br>
<center><img src="../assets/img/dl/concept/inception_motivation/1.PNG" alt="Drawing" style="width: 800px;"/></center>
<br>

- 위 슬라이드와 같이 (28 x 28 x 192) 사이즈의 인풋이 있다고 가정해 보겠습니다. 
- 인셉션 네트워크는 필터의 크기를 정하지 않고 합성곱 또는 풀링층을 모두 사용하는 것입니다. 
- 먼저 예를 들어 (1 x 1) 필터 64개를 사용하여 합성곱을 하면 (28 x 28 x 64) 크기의 출력을 가집니다.
- 다음으로 (3 x 3)필터 128개를 사용하여 합성곱을 하여(28 x 28 x 128) 크기의 출력을 가지게 만듭니다.
    - 이 때 (3 x 3)필터를 사용하였으므로 행과 열의 사이즈를 유지하려면 패딩이 필요합니다.
- 이번에는 (5 x 5)필터를 32개 사용하여 합성곱을 하여 (28 x 28 x 32) 크기의 출력을 가지게 만듭니다. 물론 이 때에도 패딩을 적용합니다.
- 그리고 이번에는 약간 특이한 맥스 풀링을 적용해 보려고 합니다. 맥스 풀링을 적용할 때, 패딩을 같이 적용하여 인풋의 행열 크기와 똑같이 만들어 보는 것입니다. 풀링의 역할이 인풋의 크기를 줄이는 데 패딩으로 사이즈를 유지시키는 것이지요.
- 최종적으로 이 결과물들을 모두 합쳐보겠습니다. 그러면 채널의 크기는 (64 + 128 + 32 + 32) = 256이 됩니다. 
    - 따라서 위 인셉션 모듈은 (28 x 28 x 192)크기를 인풋으로 가지고 출력으로 (28 x 28 x 256)의 크기를 가집니다.
    - 이렇게 네트워크를 만드는 구조가 바로 `Inception` 네트워크의 핵심입니다.
- `Inception` 네트워크에서는 필터의 크기나 풀링을 결정하는 대신 그것들을 모두 다 적용해서 출력들을 엮어낸 뒤 네트워크가 원하는 변수나 필터 크기의 조합을 학습하게 만듭니다. 

<br>

- 하지만 이렇게 네트워크를 구성하면 약간의 문제가 있습니다. 바로 `계산 비용`입니다.

<br>
<center><img src="../assets/img/dl/concept/inception_motivation/2.PNG" alt="Drawing" style="width: 800px;"/></center>
<br>

- 위 슬라이드에서 (5 x 5)필터로 만들어진 블록의 계산 비용에 대하여 알아보도록 하겠습니다.
- 먼저 (5 x 5)필터 32개로 convolution 연산 및 패딩을 하면 (28 x 28 x 192)를 (28 x 28 x 32)로 만들 수 있습니다. 
- 먼저 32개의 필터가 있고 각 필터의 사이즈는 (5 x 5 x 192)입니다.
- 출력에는 총 (28 x 28 x32)개의 숫자가 있습니다. 이 숫자들은 인풋과 필터의 연산으로 만들어진 숫자들 입니다.
    - 이 각각의 숫자들은 (5 x 5 x 192)번의 **곱셈**이 발생하게 됩니다.
- 따라서 위 슬라이드의 인풋 → 출력으로 변하는 데 발생하는 곱셈의 횟수는 (28 x 28 x 32) x (5 x 5 x 192) = ‭120,422,400‬번 입니다. 상당히 많은 횟수이지요.
- 이 정도의 계산 비용은 감당할 수는 있지만 그래도 여전히 큰 계산 비용입니다. 
- 이전 글에서 다룬 `1 x 1 convolution`을 이용하면 이 계산 비용을 약 1/10 수준으로 줄일 수 있습니다.

<br>
<center><img src="../assets/img/dl/concept/inception_motivation/3.PNG" alt="Drawing" style="width: 800px;"/></center>
<br>

- 먼저 인풋을 (1 X 1) 필터를 이용하여 채널의 수를 줄여보겠습니다. 위 예제에서는 (1 X 1 X 192)필터가 16개 필요합니다.
    - 이 경우에 중간 단의 크기를 참조하면 (28 X 28 X 16)개의 출력이 있고 각각의 출력은 (1 X 1 X 192)번의 곱셈이 발생하므로 약 240만 정도의 곱셈이 발생하였습니다.
- 같은 원리로 중간 단에서 끝단 까지 연산할 때 사용된 곱셈의 횟수를 계산해 보면 총 출력의 갯수는 (28 X 28 X 32)이고 곱셈의 연산 횟수는 (5 X 5 X 16)번 이므로 약 1천만 정도입니다.
- 따라서 1천만 + 240만을 하면 약 1.2천만번의 곱셈 연산이 발생한 것을 알 수 있습니다.
- 따라서 이전 슬라이드의 결과와 비교하면 약 1/10의 수준으로 줄인 것을 알 수 있습니다.
- 참고로 곱셈의 횟수만 따지고 덧셈의 횟수는 생략한 것은 곱셈의 횟수와 유사하게 덧셈의 횟수가 발생하므로 그 추이만 파악하는 데에는 궂이 덧셈의 횟수는 고려하지 않아도 되기 때문입니다.
    - 물론 전체 연산의 횟수를 따지려면 덧셈의 횟수도 고려해야 합니다.
- 전체적인 네트워크 구조를 보면 가운데가 홀쪽한 해지는 모양처럼 보이는 데 이것을 `Bottleneck layer`라고도 합니다.

<br>

- 정리하면 `Inception`에서의 전체적인 컨셉은 (1 x 1), (3 x 3), (5 x 5) 필터 등을 다 사용하여 합치는 구조로 성능을 최대화 해보려고 하는 것입니다.
- 이 때 발생할 수 있는 계산 비용문제는 (1 x 1) convolution 즉, `bottleneck`구조로 개선해보는 것이 특징이 됩니다.

 

   